{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Create pipeline manually\n\nSample file to create a pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First of all, lets import the main libraries and load the iris data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generic\nimport os\nimport yaml\nimport time\nimport torch\nimport pickle\nimport pprint\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Libraries\nfrom pathlib import Path\n\n# Own\nfrom ls2d.utils import _load_pickle\nfrom ls2d.utils import _dump_pickle\nfrom ls2d.utils import AttrDict\nfrom ls2d.pipeline import PipelineMemory\n\n# ------------------\n# Load config\n# ------------------\n# Configuration file\nYAML_PATH = '../datasets/iris/settings.iris.yaml'\n\n# Load configuration from file\nwith open(YAML_PATH) as file:\n    CONFIG = AttrDict(yaml.full_load(file))\n\n# ------------------\n# Load data\n# ------------------\n# Load data\ndata = pd.read_csv('..' / Path(CONFIG.filepath))\ndata = data.dropna(how='any', subset=CONFIG.features)\n\n# Show\ndata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, lets create our own pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\n\n# Create pipeline\npipe_pca = Pipeline(steps=[\n    ('std', StandardScaler()),\n    ('pca', PCA(n_components=2))\n])\n\n# Fit\npipe_pca.fit(data[CONFIG.features], None)\n\n# Define pipeline path\npath = Path('./objects') / 'plot_create_pipeline_v1'\nfilename = '%s.p' % time.strftime(\"%Y%m%d-%H%M%S\")\n\n# Create folder (if it does not exist)\npath.mkdir(parents=True, exist_ok=True)\n\n# Save it in your desired path\n#_dump_pickle(path / filename, pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can create a new workbench. For the app to run, you\nneed to include the yaml configuration file and must be named\n``settings.yaml``. Also, ensure that all the paths are correct.\n\n.. code-block:: console\n\n     workbench\n       |- xxxxxx.p\n       |- std-pca/xxxxx.p\n       |- settings.yaml\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition, it is possible to copy the created pipeline into an\nexisting workbench. Ensure that the created pipeline is compatible\nwith the existing workbench configuration.\n\n.. code-block:: console\n\n  $ cp <path_pipe> ../outputs/workbench/manual/xxxx.p\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The search.py file computes the performance metrics and\n          stores them in the ``results.csv`` file within the workbench.\n          Since we have not used that script to generate the models,\n          the performance metrics are not available and thus they do\n          not appear in the app.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the server et voila!\n\n.. code-block:: console\n\n $ python server.py\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a pipeline wih our own algorithm.\n\nBy inheriting from ``BaseEstimator`` we include the methods ``get_params()``\nand ``set_params()`` from such class. This might be useful and also helps\nto display the pipeline name nicely. Similarly, by inheriting from\n``TransformerMixin`` we include the methot ``fit_transform()``.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The last step of a sklearn ``Pipeline`` must implement the method\n          fit!</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import base libraries from sklearn\nfrom sklearn.base import BaseEstimator    # get_params(), set_params()\nfrom sklearn.base import TransformerMixin # fit_transform()\n\nclass First(BaseEstimator, TransformerMixin):\n    def __init__(self, n):\n        self.n = n\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        return X[:,:self.n]\n\n# Create pipeline\npipe_first = Pipeline(steps=[\n    ('std', StandardScaler()),\n    ('first', First(n=2))\n])\n\n# Fit\npipe_first.fit(data[CONFIG.features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets see the PCA embeddings\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import ploty\nimport plotly.express as px\n\n# Compute embeddings\ndata[['x', 'y']] = pipe_pca.transform(data[CONFIG.features])\n\n# Display\nfig = px.scatter(data, x=\"x\", y=\"y\", color=\"label\",\n    hover_data=data.columns.tolist(),\n    color_discrete_sequence=px.colors.qualitative.Pastel2,\n    template='none', title=str(pipe_pca))\n\n# Show\nfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualise all the embeddings (in your local machine)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i,p in enumerate([pipe_pca, pipe_first]):\n\n    # Compute embeddings\n    data[['x', 'y']] = p.transform(data[CONFIG.features])\n\n    # Display\n    fig = px.scatter(data, x=\"x\", y=\"y\", color=\"label\",\n                     hover_data=data.columns.tolist(),\n                     color_discrete_sequence=px.colors.qualitative.Pastel2,\n                     template='none', title=str(p))\n\n    # Show (uncomment)\n    #fig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}