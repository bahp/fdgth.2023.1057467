{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Create pipeline (pretrained)\n\nSample file to create a pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First of all, lets import the main libraries and load the iris data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generic\nimport os\nimport yaml\nimport time\nimport torch\nimport pickle\nimport pprint\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Libraries\nfrom pathlib import Path\n\n# Own\nfrom ls2d.utils import _load_pickle\nfrom ls2d.utils import _dump_pickle\nfrom ls2d.utils import AttrDict\nfrom ls2d.pipeline import PipelineMemory\n\n# ------------------\n# Load config\n# ------------------\n# Configuration file\nYAML_PATH = '../datasets/iris/settings.iris.yaml'\n\n# Load configuration from file\nwith open(YAML_PATH) as file:\n    CONFIG = AttrDict(yaml.full_load(file))\n\n# ------------------\n# Load data\n# ------------------\n# Load data\ndata = pd.read_csv('..' / Path(CONFIG.filepath))\ndata = data.dropna(how='any', subset=CONFIG.features)\n\n# Show\ndata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, lets create our own pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nclass Sample:\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        return X[:,:2]\n\n\n# Create pipeline\npipe = Pipeline(steps=[\n    ('std', StandardScaler()),\n    ('smp', Sample())\n])\n\n# Fit\npipe.fit(data[CONFIG.features], None)\n\n# Define pipeline path\npath = Path('./objects') / 'plot_create_pipeline_v1'\nfilename = '%s.p' % time.strftime(\"%Y%m%d-%H%M%S\")\n\n# Create folder (if it does not exist)\npath.mkdir(parents=True, exist_ok=True)\n\n# Save it in your desired path\n#_dump_pickle(path / filename, pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can create a new workbench. For the app to run, you\nneed to include the yaml configuration file and must be named\n``settings.yaml``. Also, ensure that all the paths are correct.\n\n.. code-block:: console\n\n     workbench\n       |- xxxxxx.p\n       |- std-pca/xxxxx.p\n       |- settings.yaml\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition, it is possible to copy the created pipeline into an\nexisting workbench. Ensure that the created pipeline is compatible\nwith the existing workbench configuration.\n\n.. code-block:: console\n\n  $ cp <path_pipe> ../outputs/workbench/manual/xxxx.p\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The search.py file computes the performance metrics and\n          stores them in the ``results.csv`` file within the workbench.\n          Since we have not used that script to generate the models,\n          the performance metrics are not available and thus they do\n          not appear in the app.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the server et voila!\n\n.. code-block:: console\n\n $ python server.py\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets use the pipeline locally\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute embeddings\ndata[['x', 'y']] = pipe.transform(data[CONFIG.features])\n\n# Import ploty\nimport plotly.express as px\n\n# The possible templates are [\"plotly\", \"plotly_white\", \"plotly_dark\",\n# \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]:\n\n# Display\nfig = px.scatter(data, x=\"x\", y=\"y\", color=\"label\",\n    hover_data=data.columns.tolist(),\n    color_discrete_sequence=px.colors.qualitative.Pastel2,\n    template='none')\n\n# Show\nfig"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}